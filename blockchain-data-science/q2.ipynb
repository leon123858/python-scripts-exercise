{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Q2\n",
    "\n",
    "題目: 分析 ETH 合約 **UniswapV3**\n",
    "\n",
    "回答(查询30天內)\n",
    "\n",
    "- 不同费率的流动资金池数量\n",
    "- 按周汇总的新建流动资金池总数\n",
    "- 每日新建流动资金池总数\n",
    "- 统计资金池数量最多的代币Token\n",
    "- 最新的100个流动资金池记录\n",
    "\n",
    "在官網找到解說和地址:\n",
    "\n",
    "https://gov.uniswap.org/t/official-uniswap-v3-deployments-list/24323\n",
    "\n",
    "在 OKLink 做基本檢視\n",
    "\n",
    " https://www.oklink.com/zh-hant/ethereum/address/0x1f98431c8ad98523631ae4a59f267346ea31f984\n",
    "\n",
    "核心概念是 `Uniswap` 合約可以創建流動性資金池\n",
    "\n",
    "所以只要分析 ETH Event 中該合約創建資金池的 Event 即可\n",
    "\n",
    "根據上圖可以得知合約事件的參數\n",
    "\n",
    "- token0: event id\n",
    "- token1: coin1 addr\n",
    "- token2: coin2 addr\n",
    "\n",
    "使用以下 query\n",
    "\n",
    "```bash\n",
    "SELECT\n",
    "  block_timestamp AS block_time,\n",
    "  topics[SAFE_OFFSET(1)] AS topic1,\n",
    "  topics[SAFE_OFFSET(2)] AS topic2,\n",
    "  topics[SAFE_OFFSET(3)] AS topic3,\n",
    "  transaction_hash AS tx_hash\n",
    "FROM\n",
    "  `bigquery-public-data.crypto_ethereum.logs`\n",
    "WHERE\n",
    "  address = LOWER('0x1F98431c8aD98523631AE4a59f267346ea31F984')\n",
    "  AND topics[SAFE_OFFSET(0)] = LOWER('0x783cca1c0412dd0d695e784568c96da2e9c22ff989357a2e8b1d9b2b4e6b7118')\n",
    "  AND (DATE(block_timestamp) >= '2025-11-1' AND DATE(block_timestamp) < '2025-12-1')\n",
    "```\n",
    "\n",
    "得到 data候用以下程式碼計算"
   ],
   "id": "8480ec540d657ffd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "# SELECT\n",
    "#   block_timestamp AS block_time,\n",
    "#   topics[SAFE_OFFSET(1)] AS topic1,\n",
    "#   topics[SAFE_OFFSET(2)] AS topic2,\n",
    "#   topics[SAFE_OFFSET(3)] AS topic3,\n",
    "#   transaction_hash AS tx_hash\n",
    "# FROM\n",
    "#   `bigquery-public-data.crypto_ethereum.logs`\n",
    "# WHERE\n",
    "#   address = LOWER('0x1F98431c8aD98523631AE4a59f267346ea31F984')\n",
    "#   AND topics[SAFE_OFFSET(0)] = LOWER('0x783cca1c0412dd0d695e784568c96da2e9c22ff989357a2e8b1d9b2b4e6b7118')\n",
    "#   AND (DATE(block_timestamp) >= '2025-11-1' AND DATE(block_timestamp) < '2025-12-1')\n",
    "\n",
    "def process_ethereum_logs(file_path):\n",
    "    # 1. 定義欄位名稱\n",
    "    # 原始數據的 \"block_time\" 包含空格 (例如: 2025-11-24 22:18:11 UTC)\n",
    "    # read_csv 遇到空格會切分，所以我們手動定義 date, time, tz 三個欄位來接住它\n",
    "    cols = ['date', 'time', 'tz', 'topic1', 'topic2', 'topic3', 'tx_hash']\n",
    "\n",
    "    try:\n",
    "        # 2. 讀取 data.txt\n",
    "        # sep=r'\\s+' 表示以任意數量的空格或 Tab 作為分隔符\n",
    "        # skiprows=1 表示跳過原本檔案裡的第一行標題 (因為我們要用自定義的 cols)\n",
    "        df = pd.read_csv(file_path, sep=r'\\s+', skiprows=1, names=cols)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"錯誤: 找不到檔案 {file_path}，請確認檔案位置。\")\n",
    "        return\n",
    "\n",
    "    # 3. 輔助函數：清洗數據\n",
    "    def decode_address(hex_str):\n",
    "        # 處理可能的 NaN 或非字串情況\n",
    "        if not isinstance(hex_str, str): return hex_str\n",
    "        # 取最後 40 個字元 (20 bytes) 並補回 0x\n",
    "        return '0x' + hex_str[-40:]\n",
    "\n",
    "    def decode_int(hex_str):\n",
    "        # 將 Hex 轉為十進位整數\n",
    "        try:\n",
    "            return int(hex_str, 16)\n",
    "        except (ValueError, TypeError):\n",
    "            return 0\n",
    "\n",
    "    # 4. 應用轉換邏輯\n",
    "    # 合併時間欄位\n",
    "    df['block_time'] = pd.to_datetime(df['date'] + ' ' + df['time'])\n",
    "\n",
    "    # 解析地址 (Topic1, Topic2)\n",
    "    df['topic1_parsed'] = df['topic1'].apply(decode_address)\n",
    "    df['topic2_parsed'] = df['topic2'].apply(decode_address)\n",
    "\n",
    "    # 解析數值 (Topic3)\n",
    "    df['topic3_decimal'] = df['topic3'].apply(decode_int)\n",
    "\n",
    "    # 5. 整理最終輸出表格\n",
    "    # 只選取處理好的欄位，並重新排序\n",
    "    final_view = df[['block_time', 'topic1_parsed', 'topic2_parsed', 'topic3_decimal', 'tx_hash']]\n",
    "\n",
    "    return final_view\n",
    "\n",
    "\n",
    "# 執行主程式\n",
    "if __name__ == \"__main__\":\n",
    "    result_df = process_ethereum_logs('data.txt')\n",
    "\n",
    "    # 不同费率的流动资金池数量\n",
    "    q1_ret = result_df.groupby(\"topic3_decimal\").count().reset_index()\n",
    "    print(q1_ret.head(10))\n",
    "\n",
    "    # 按周汇总的新建流动资金池总数\n",
    "    q2_ret = result_df.copy()\n",
    "    q2_ret['block_time'] = q2_ret['block_time'].dt.isocalendar().week\n",
    "    q2_ret = q2_ret.groupby('block_time').count().reset_index()\n",
    "    print(q2_ret.head())\n",
    "\n",
    "    #每日新建流动资金池总数\n",
    "    q3_ret = result_df.copy()\n",
    "    q3_ret['date_str'] = q3_ret['block_time'].dt.strftime('%Y-%m-%d')\n",
    "    q3_ret = q3_ret.groupby('date_str').count().reset_index()\n",
    "    print(q3_ret.head())\n",
    "\n",
    "    # 统计资金池数量最多的代币Token\n",
    "    part1 = result_df[['tx_hash', 'topic1_parsed']].rename(columns={'topic1_parsed': 'token'})\n",
    "    part2 = result_df[['tx_hash', 'topic2_parsed']].rename(columns={'topic2_parsed': 'token'})\n",
    "    q4_ret = pd.concat([part1, part2], ignore_index=True)\n",
    "    q4_ret = q4_ret.groupby('token').count().reset_index()\n",
    "    print(q4_ret.sort_values(\"tx_hash\", ascending=False).head(20))\n",
    "\n",
    "    # 最新的100个流动资金池记录\n",
    "    q5_ret = result_df.sort_values(\"block_time\", ascending=False).head(20)\n",
    "    print(q5_ret.head(20))"
   ],
   "id": "404d0f11dc4ee244"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
